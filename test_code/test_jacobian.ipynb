{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from functorch import make_functional, grad\n",
    "from torch.func import functional_call, grad, vmap, vjp, jacrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(20, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 20),\n",
    "        nn.ReLU(),\n",
    "    ),\n",
    "    nn.Linear(20, 2),\n",
    "    nn.Softmax(dim=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4415, 0.5585],\n",
       "        [0.4435, 0.5565],\n",
       "        [0.4496, 0.5504],\n",
       "        [0.4564, 0.5436],\n",
       "        [0.4343, 0.5657],\n",
       "        [0.4360, 0.5640],\n",
       "        [0.4431, 0.5569],\n",
       "        [0.4652, 0.5348],\n",
       "        [0.4528, 0.5472],\n",
       "        [0.4502, 0.5498]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# func, params = make_functional(model)\n",
    "functional_call(model, dict(model.named_parameters()), torch.randn(10, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = jacrev(lambda params, input: functional_call(model, params, input), argnums=0)(dict(model.named_parameters()), torch.randn(117, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([10, 3]) torch.Size([117, 2, 10, 3])\n",
      "0.bias torch.Size([10]) torch.Size([117, 2, 10])\n",
      "2.weight torch.Size([20, 10]) torch.Size([117, 2, 20, 10])\n",
      "2.bias torch.Size([20]) torch.Size([117, 2, 20])\n",
      "4.0.weight torch.Size([10, 20]) torch.Size([117, 2, 10, 20])\n",
      "4.0.bias torch.Size([10]) torch.Size([117, 2, 10])\n",
      "4.2.weight torch.Size([20, 10]) torch.Size([117, 2, 20, 10])\n",
      "4.2.bias torch.Size([20]) torch.Size([117, 2, 20])\n",
      "5.weight torch.Size([2, 20]) torch.Size([117, 2, 2, 20])\n",
      "5.bias torch.Size([2]) torch.Size([117, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "dict_param = dict(model.named_parameters())\n",
    "for key in dict_param.keys():\n",
    "    print(key, dict_param[key].shape, result[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0450,  2.6428, -0.5227],\n",
       "         [ 0.3608,  1.1736,  0.5707],\n",
       "         [-0.1223, -0.3912,  0.6274],\n",
       "         [ 0.0113, -0.0442, -0.9692]],\n",
       "\n",
       "        [[-1.0180, -1.2155,  0.8685],\n",
       "         [-0.2046, -0.9934, -0.7542],\n",
       "         [ 1.2549,  0.0188, -0.4634],\n",
       "         [-0.2680,  0.7302,  1.9944]],\n",
       "\n",
       "        [[ 0.0304,  0.8716,  0.0114],\n",
       "         [-0.8623, -1.1859, -0.0055],\n",
       "         [-0.2921, -0.5316,  1.0583],\n",
       "         [ 0.9751, -0.6307,  0.3232]],\n",
       "\n",
       "        [[ 0.4677, -0.1208,  1.5119],\n",
       "         [-1.4177, -1.2684,  0.0795],\n",
       "         [ 0.0352,  0.3082, -0.5326],\n",
       "         [ 0.7714, -0.8671,  0.0601]],\n",
       "\n",
       "        [[-0.8817,  0.4520, -1.0624],\n",
       "         [-0.9823, -0.1784,  1.8584],\n",
       "         [-0.0661, -1.5817,  0.2411],\n",
       "         [-2.2205, -0.6710, -1.9523]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5,4,3) * np.ones((5,4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forl-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
