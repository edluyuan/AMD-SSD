{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(\n",
    "    input_size=32,\n",
    "    hidden_size=32,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for p in lstm.parameters():\n",
    "#     print(p.shape)\n",
    "#     print(np.zeros(p.shape).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.randn(11, 10, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = dict(lstm.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacrev(\n",
    "#     lambda params: lstm(input_batch)\n",
    "# )(dict_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 10, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tuple(dict(lstm.named_parameters()).values())\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacobian(\n",
    "#     lambda *params: lstm(input_batch),\n",
    "#     params,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.backends.cudnn.flags(enabled=False):\n",
    "    output, _ = lstm(input_batch)\n",
    "outputs = output.mean((-1, -2))\n",
    "ones = torch.ones_like(outputs, requires_grad=True)\n",
    "gradd = grad(outputs, lstm.parameters(), grad_outputs=ones, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.1624e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "(tensor([ 2.0814e-04, -2.1434e-04,  7.4781e-06,  9.1956e-05,  6.8082e-05,\n",
      "         2.2094e-04,  7.1476e-05, -2.2327e-04,  3.1089e-05,  7.6912e-05,\n",
      "        -3.9009e-04], device='cuda:0'),)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "(tensor([ 5.9530e-05, -2.8128e-05,  3.1103e-05,  3.0879e-05, -1.7524e-05,\n",
      "        -8.9796e-07, -2.1409e-05,  9.6220e-06,  3.8628e-05,  3.2034e-05,\n",
      "         4.0374e-05], device='cuda:0'),)\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "(tensor([0.0027, 0.0023, 0.0025, 0.0025, 0.0025, 0.0025, 0.0024, 0.0027, 0.0025,\n",
      "        0.0025, 0.0028], device='cuda:0'),)\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "(tensor([0.0027, 0.0023, 0.0025, 0.0025, 0.0025, 0.0025, 0.0024, 0.0027, 0.0025,\n",
      "        0.0025, 0.0028], device='cuda:0'),)\n"
     ]
    }
   ],
   "source": [
    "for g in gradd:\n",
    "    print(g.mean())\n",
    "    results = grad(g.mean(), ones, retain_graph=True)\n",
    "    print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.func import functional_call, jacrev, jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func_call(params, input_batch):\n",
    "#     output, _ = functional_call(lstm, params, input_batch)\n",
    "#     return output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jac = jacrev(\n",
    "#     lambda params: func_call(params=params, input_batch=input_batch),\n",
    "#     argnums=0\n",
    "# )(dict_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an error from pytorch so It is really hard to calculate jacobian with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jac = jacfwd(\n",
    "#     lambda params: func_call(params=params, input_batch=input_batch),\n",
    "#     argnums=0\n",
    "# )(dict_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forl-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
